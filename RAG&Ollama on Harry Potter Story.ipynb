{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1itHDlZjO5m4ig6_2iJAiHB5u-50GhOL5","timestamp":1712033721976}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[Youtube影片解說](https://youtu.be/HtqmEREAPC0?si=lMwDebm6opyw5FHW)"],"metadata":{"id":"rYb6aNDXVy_M"}},{"cell_type":"code","source":["{\n","\"model\": \"llama2\"\n","}"],"metadata":{"id":"I5N1s91LdCKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fUWJhAFMDDUD"},"outputs":[],"source":["import json\n","import gradio as gr\n","\n","from langchain_community.chat_models import ChatOllama\n","from langchain_core.prompts import PromptTemplate\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain_community.vectorstores import Chroma\n","from langchain_community.embeddings import FastEmbedEmbeddings\n","from langchain.vectorstores.utils import filter_complex_metadata\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.output_parsers import StrOutputParser\n","\n","\n","\n","#Create the prompte from the template.\n","promptTemplate = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n","    not contained in the context, say \"answer not available in context\" \\n\\n\n","    Context: {context}\n","    Question: {question}\n","    Answer:\n","\n","     \"\"\"\n","modelSel = \"\"\n","#Load the PDF file to ChromaDB\n","def loadDataFromPDFFile(filePath):\n","    loader = PyPDFLoader(filePath)\n","    pages = loader.load_and_split()\n","    chunks = filter_complex_metadata(pages)\n","    vector_store = Chroma.from_documents(documents=chunks, embedding=FastEmbedEmbeddings())\n","    return vector_store\n","\n","\n","\n","def modelResponse(message , history):\n","    llm = ChatOllama(model = conf[\"model\"])\n","\n","    prompt = PromptTemplate(template=promptTemplate , input_variables=[\"context\",\"question\"])\n","\n","    #Initiate the retriever\n","    dbLoaded = loadDataFromPDFFile(\"~/Desktop/hp/HP1.pdf\")\n","    retriever = dbLoaded.as_retriever(search_type=\"similarity_score_threshold\" , search_kwargs = {\n","        \"k\": 5,\n","        \"score_threshold\": 0.2\n","    })\n","    hpChain = (\n","            {\"context\": retriever , \"question\": RunnablePassthrough()}\n","            | prompt\n","            | llm\n","            | StrOutputParser()\n","    )\n","    return hpChain.invoke(message)\n","\n","\n","if __name__ == \"__main__\":\n","\n","    #read configuration file\n","    conf = {}\n","    with open(\"config.json\" , \"r\") as confFile:\n","        conf = json.load(confFile)\n","        print(conf[\"model\"])\n","\n","    chatUI = gr.ChatInterface(fn=modelResponse , title=\"Harry Potter Story Q&A\")\n","    chatUI.launch()\n"]}]}